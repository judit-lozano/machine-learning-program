{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#04. Why Neural Networks Deeply Learn a Mathematical Formula?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Book + Private Lessons [Here ‚Üó](https://sotastica.com/reservar)\n",
    "- Subscribe to my [Blog ‚Üó](https://blog.pythonassembly.com/)\n",
    "- Let's keep in touch on [LinkedIn ‚Üó](www.linkedin.com/in/jsulopz) üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Machine Learns...\n",
    ">\n",
    "> But, **what does it learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the Machine Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practical Example ‚Üí [Tesla Autopilot](https://www.tesla.com/AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example where It Fails ‚Üí [Tesla Confuses Moon with Semaphore](https://twitter.com/Carnage4Life/status/1418920100086784000?s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Simply execute the following lines of code to load the data.\n",
    "> - This dataset contains **statistics about Car Accidents** (columns)\n",
    "> - In each one of **USA States** (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>5.9</td>\n",
       "      <td>2.006</td>\n",
       "      <td>1.593</td>\n",
       "      <td>5.900</td>\n",
       "      <td>5.900</td>\n",
       "      <td>1273.89</td>\n",
       "      <td>136.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.640</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.040</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NV</th>\n",
       "      <td>14.7</td>\n",
       "      <td>5.439</td>\n",
       "      <td>4.704</td>\n",
       "      <td>13.965</td>\n",
       "      <td>14.553</td>\n",
       "      <td>1029.87</td>\n",
       "      <td>138.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>23.9</td>\n",
       "      <td>9.082</td>\n",
       "      <td>9.799</td>\n",
       "      <td>22.944</td>\n",
       "      <td>19.359</td>\n",
       "      <td>858.97</td>\n",
       "      <td>116.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>18.2</td>\n",
       "      <td>9.100</td>\n",
       "      <td>5.642</td>\n",
       "      <td>17.472</td>\n",
       "      <td>16.016</td>\n",
       "      <td>905.99</td>\n",
       "      <td>153.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "DC        5.9     2.006    1.593           5.900        5.900      1273.89   \n",
       "AL       18.8     7.332    5.640          18.048       15.040       784.55   \n",
       "NV       14.7     5.439    4.704          13.965       14.553      1029.87   \n",
       "SC       23.9     9.082    9.799          22.944       19.359       858.97   \n",
       "PA       18.2     9.100    5.642          17.472       16.016       905.99   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "DC          136.05  \n",
       "AL          145.08  \n",
       "NV          138.71  \n",
       "SC          116.29  \n",
       "PA          153.86  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the `Weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/initializers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 18:19:37.332711: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-15 18:19:37.366459: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc46e6e3dd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-15 18:19:37.366473: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='zeros'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-1.198971 ],\n",
       "        [-0.8542514],\n",
       "        [-0.5962893]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 198.9468 - mse: 198.9468\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 36.7605 - mse: 36.7605\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.5509 - mse: 27.5509\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 956us/step - loss: 28.3127 - mse: 28.3127\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4104 - mse: 27.4104\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 923us/step - loss: 26.6115 - mse: 26.6115\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 783us/step - loss: 26.5767 - mse: 26.5767\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 771us/step - loss: 26.1284 - mse: 26.1284\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.5844 - mse: 25.5844\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.7333 - mse: 25.7333\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.3078 - mse: 27.3078\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.5103 - mse: 28.5103\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.1297 - mse: 26.1297\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.6659 - mse: 24.6659\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 911us/step - loss: 23.6926 - mse: 23.6926\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.9382 - mse: 24.9382\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 29.9830 - mse: 29.9830\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.0944 - mse: 27.0944\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.0997 - mse: 30.0997\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.0326 - mse: 23.0326\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.2210 - mse: 22.2210\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.8826 - mse: 21.8826\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 893us/step - loss: 20.1023 - mse: 20.1023\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.9388 - mse: 22.9388\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.7667 - mse: 26.7667\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.8695 - mse: 21.8695\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.6461 - mse: 18.6461\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.3738 - mse: 21.3738\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.5358 - mse: 18.5358\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 925us/step - loss: 24.4536 - mse: 24.4536\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 944us/step - loss: 20.3076 - mse: 20.3076\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.2434 - mse: 18.2434\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.7541 - mse: 16.7541\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.1330 - mse: 16.1330\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8911 - mse: 15.8911\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.3662 - mse: 15.3662\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2646 - mse: 15.2646\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7729 - mse: 15.7729\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.1040 - mse: 16.1040\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.7305 - mse: 20.7305\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.5584 - mse: 15.5584\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4585 - mse: 17.4585\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.7669 - mse: 15.7669\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.7364 - mse: 14.7364\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.5024 - mse: 15.5024\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.3079 - mse: 12.3079\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.9987 - mse: 11.9987\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 917us/step - loss: 12.3893 - mse: 12.3893\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.1521 - mse: 18.1521\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.9559 - mse: 19.9559\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9291 - mse: 10.9291\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7649 - mse: 10.7649\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6029 - mse: 11.6029\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4757 - mse: 10.4757\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 867us/step - loss: 15.2021 - mse: 15.2021\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.7825 - mse: 13.7825\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1974 - mse: 10.1974\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.0172 - mse: 14.0172\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2715 - mse: 12.2715\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5145 - mse: 9.5145\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9209 - mse: 8.9209\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2268 - mse: 12.2268\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7053 - mse: 13.7053\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4090 - mse: 8.4090\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1467 - mse: 8.1467\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0647 - mse: 8.0647\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8324 - mse: 7.8324\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3059 - mse: 13.3059\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.9891 - mse: 18.9891\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8005 - mse: 7.8005\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 893us/step - loss: 8.3898 - mse: 8.3898\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.0060 - mse: 12.0060\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 887us/step - loss: 9.2545 - mse: 9.2545\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9653 - mse: 6.9653\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2324 - mse: 7.2324\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2785 - mse: 7.2785\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 6.7688 - mse: 6.7688\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4041 - mse: 7.4041\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.6971 - mse: 6.6971\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 903us/step - loss: 8.7428 - mse: 8.7428\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5740 - mse: 12.5740\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7436 - mse: 8.7436\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.8193 - mse: 5.8193\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2518 - mse: 7.2518\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 5.6167 - mse: 5.6167\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2404 - mse: 7.2404\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 904us/step - loss: 5.9989 - mse: 5.9989\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.7901 - mse: 5.7901\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.5747 - mse: 5.5747\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.8544 - mse: 4.8544\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7925 - mse: 4.7925\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.5343 - mse: 13.5343\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 938us/step - loss: 11.2057 - mse: 11.2057\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8288 - mse: 4.8288\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.5470 - mse: 5.5470\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5678 - mse: 6.5678\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3173 - mse: 4.3173\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.1841 - mse: 5.1841\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3426 - mse: 4.3426\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.6349 - mse: 4.6349\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.1903 - mse: 6.1903\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9603 - mse: 4.9603\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4233 - mse: 4.4233\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8123 - mse: 9.8123\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 912us/step - loss: 9.8452 - mse: 9.8452\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.7819 - mse: 5.7819\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 866us/step - loss: 3.6978 - mse: 3.6978\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.7780 - mse: 3.7780\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.5014 - mse: 3.5014\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3814 - mse: 3.3814\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9596 - mse: 3.9596\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.1184 - mse: 5.1184\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 6.8306 - mse: 6.8306\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6939 - mse: 9.6939\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1135 - mse: 8.1135\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.0544 - mse: 4.0544\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2592 - mse: 3.2592\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2623 - mse: 3.2623\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3566 - mse: 3.3566\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2426 - mse: 4.2426\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4720 - mse: 4.4720\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.6489 - mse: 4.6489\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1903 - mse: 3.1903\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7875 - mse: 2.7875\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9210 - mse: 2.9210\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2301 - mse: 3.2301\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7359 - mse: 2.7359\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 759us/step - loss: 2.6380 - mse: 2.6380\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.4963 - mse: 3.4963\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6874 - mse: 13.6874\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 966us/step - loss: 8.6179 - mse: 8.6179\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7486 - mse: 4.7486\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9033 - mse: 2.9033\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6365 - mse: 2.6365\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1652 - mse: 3.1652\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 950us/step - loss: 4.2638 - mse: 4.2638\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 930us/step - loss: 4.4304 - mse: 4.4304\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.0294 - mse: 5.0294\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6750 - mse: 2.6750\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3416 - mse: 2.3416\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4635 - mse: 2.4635\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.5489 - mse: 3.5489\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.5593 - mse: 6.5593\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 949us/step - loss: 4.2534 - mse: 4.2534\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8906 - mse: 3.8906\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 904us/step - loss: 2.5130 - mse: 2.5130\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6287 - mse: 2.6287\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4754 - mse: 4.4754\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.5607 - mse: 6.5607\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0115 - mse: 8.0115\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0389 - mse: 3.0389\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3406 - mse: 2.3406\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 716us/step - loss: 2.6411 - mse: 2.6411\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7970 - mse: 2.7970\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8840 - mse: 4.8840\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.8301 - mse: 5.8301\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.3284 - mse: 5.3284\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2957 - mse: 3.2957\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3203 - mse: 2.3203\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9607 - mse: 1.9607\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9295 - mse: 1.9295\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.9685 - mse: 5.9685\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 823us/step - loss: 8.8187 - mse: 8.8187\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 2.5074 - mse: 2.5074\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4311 - mse: 2.4311\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1046 - mse: 4.1046\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1602 - mse: 4.1602\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5978 - mse: 2.5978\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 956us/step - loss: 2.5354 - mse: 2.5354\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 902us/step - loss: 2.9982 - mse: 2.9982\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8889 - mse: 4.8889\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6199 - mse: 3.6199\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3380 - mse: 3.3380\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7822 - mse: 2.7822\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8367 - mse: 1.8367\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1445 - mse: 2.1445\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.4725 - mse: 4.4725\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 934us/step - loss: 4.9671 - mse: 4.9671\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.7507 - mse: 3.7507\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5657 - mse: 2.5657\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6784 - mse: 3.6784\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2528 - mse: 9.2528\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.4934 - mse: 6.4934\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1934 - mse: 2.1934\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9332 - mse: 1.9332\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4091 - mse: 2.4091\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0804 - mse: 3.0804\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.0631 - mse: 4.0631\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4945 - mse: 4.4945\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3492 - mse: 3.3492\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4551 - mse: 2.4551\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 809us/step - loss: 2.9986 - mse: 2.9986\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 887us/step - loss: 3.2670 - mse: 3.2670\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1470 - mse: 4.1470\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 774us/step - loss: 2.8726 - mse: 2.8726\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4588 - mse: 2.4588\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9409 - mse: 3.9409\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6991 - mse: 4.6991\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 954us/step - loss: 6.2172 - mse: 6.2172\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 3.9748 - mse: 3.9748\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6915 - mse: 1.6915\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6997 - mse: 1.6997\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6847 - mse: 1.6847\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 2.5472 - mse: 2.5472\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 887us/step - loss: 7.1161 - mse: 7.1161\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.2708 - mse: 6.2708\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 975us/step - loss: 2.8641 - mse: 2.8641\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 800us/step - loss: 2.9777 - mse: 2.9777\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2818 - mse: 2.2818\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 1.6530 - mse: 1.6530\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 913us/step - loss: 1.9272 - mse: 1.9272\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6240 - mse: 3.6240\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7227 - mse: 7.7227\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.0991 - mse: 7.0991\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9999 - mse: 1.9999\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6709 - mse: 1.6709\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8956 - mse: 1.8956\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6287 - mse: 3.6287\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.4488 - mse: 5.4488\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9937 - mse: 2.9937\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7205 - mse: 1.7205\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6283 - mse: 1.6283\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 1.6179 - mse: 1.6179\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 2.2268 - mse: 2.2268\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 940us/step - loss: 4.7633 - mse: 4.7633\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.4102 - mse: 6.4102\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.0735 - mse: 5.0735\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1070 - mse: 4.1070\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6814 - mse: 1.6814\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5727 - mse: 1.5727\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6349 - mse: 1.6349\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 766us/step - loss: 3.3367 - mse: 3.3367\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.2375 - mse: 6.2375\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8939 - mse: 4.8939\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1041 - mse: 2.1041\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5863 - mse: 1.5863\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5573 - mse: 1.5573\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5676 - mse: 1.5676\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6735 - mse: 1.6735\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2570 - mse: 2.2570\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.2105 - mse: 6.2105\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 866us/step - loss: 9.5213 - mse: 9.5213\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1584 - mse: 2.1584\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5630 - mse: 1.5630\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6321 - mse: 1.6321\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9693 - mse: 1.9693\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 942us/step - loss: 3.5719 - mse: 3.5719\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 942us/step - loss: 4.0205 - mse: 4.0205\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 813us/step - loss: 3.0938 - mse: 3.0938\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2908 - mse: 7.2908\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 4.2680 - mse: 4.2680\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8764 - mse: 1.8764\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6899 - mse: 1.6899\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 826us/step - loss: 1.7828 - mse: 1.7828\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2736 - mse: 4.2736\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 908us/step - loss: 4.1815 - mse: 4.1815\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 864us/step - loss: 2.0976 - mse: 2.0976\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 1.6987 - mse: 1.6987\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7665 - mse: 1.7665\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 1.4984 - mse: 1.4984\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5146 - mse: 1.5146\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6518 - mse: 1.6518\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 818us/step - loss: 5.6599 - mse: 5.6599\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 761us/step - loss: 12.8890 - mse: 12.8890\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 4.3866 - mse: 4.3866\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5841 - mse: 2.5841\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5731 - mse: 2.5731\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 978us/step - loss: 4.0830 - mse: 4.0830\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2200 - mse: 2.2200\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 1.9634 - mse: 1.9634\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 941us/step - loss: 3.4464 - mse: 3.4464\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7535 - mse: 4.7535\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1904 - mse: 3.1904\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 970us/step - loss: 1.6708 - mse: 1.6708\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4522 - mse: 1.4522\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0228 - mse: 2.0228\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0762 - mse: 3.0762\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 902us/step - loss: 6.8534 - mse: 6.8534\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 789us/step - loss: 5.7190 - mse: 5.7190\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 829us/step - loss: 2.2851 - mse: 2.2851\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4516 - mse: 1.4516\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8176 - mse: 1.8176\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6335 - mse: 2.6335\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 906us/step - loss: 2.9819 - mse: 2.9819\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.1768 - mse: 5.1768\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 5.1903 - mse: 5.1903\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6532 - mse: 2.6532\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8878 - mse: 1.8878\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7869 - mse: 1.7869\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0508 - mse: 2.0508\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5019 - mse: 1.5019\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7215 - mse: 1.7215\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.6489 - mse: 5.6489\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.7410 - mse: 6.7410\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.8546 - mse: 2.8546\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3014 - mse: 2.3014\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.8267 - mse: 3.8267\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.8651 - mse: 3.8651\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3114 - mse: 4.3114\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3600 - mse: 4.3600\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7384 - mse: 2.7384\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8845 - mse: 1.8845\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 2.0831 - mse: 2.0831\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4217 - mse: 1.4217\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8120 - mse: 1.8120\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3175 - mse: 3.3175\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.4787 - mse: 6.4787\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 4.5388 - mse: 4.5388\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6875 - mse: 1.6875\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 852us/step - loss: 1.4031 - mse: 1.4031\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4058 - mse: 1.4058\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0612 - mse: 2.0612\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.4870 - mse: 5.4870\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 6.3440 - mse: 6.3440\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.6805 - mse: 5.6805\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3611 - mse: 2.3611\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7244 - mse: 1.7244\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 802us/step - loss: 1.6263 - mse: 1.6263\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 970us/step - loss: 1.3759 - mse: 1.3759\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3932 - mse: 1.3932\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3901 - mse: 1.3901\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 1.4214 - mse: 1.4214\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 792us/step - loss: 2.4793 - mse: 2.4793\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 919us/step - loss: 9.6203 - mse: 9.6203\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 4.1215 - mse: 4.1215\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1305 - mse: 2.1305\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5369 - mse: 1.5369\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4797 - mse: 1.4797\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1555 - mse: 3.1555\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 5.0963 - mse: 5.0963\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.5501 - mse: 4.5501\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.4171 - mse: 3.4171\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9485 - mse: 1.9485\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 828us/step - loss: 1.6496 - mse: 1.6496\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 829us/step - loss: 2.4160 - mse: 2.4160\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6518 - mse: 4.6518\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1113 - mse: 3.1113\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.2538 - mse: 3.2538\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.8998 - mse: 5.8998\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2425 - mse: 4.2425\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6424 - mse: 1.6424\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 987us/step - loss: 1.3374 - mse: 1.3374\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 1.4895 - mse: 1.4895\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4563 - mse: 1.4563\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.2996 - mse: 5.2996\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0736 - mse: 9.0736\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7683 - mse: 4.7683\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5741 - mse: 1.5741\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5459 - mse: 1.5459\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6285 - mse: 1.6285\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4716 - mse: 1.4716\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9581 - mse: 2.9581\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 845us/step - loss: 8.3039 - mse: 8.3039\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9008 - mse: 3.9008\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0420 - mse: 2.0420\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4715 - mse: 1.4715\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9456 - mse: 1.9456\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 920us/step - loss: 1.9282 - mse: 1.9282\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 823us/step - loss: 1.9836 - mse: 1.9836\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 725us/step - loss: 1.8097 - mse: 1.8097\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 3.1204 - mse: 3.1204\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 794us/step - loss: 7.6144 - mse: 7.6144\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 792us/step - loss: 4.8991 - mse: 4.8991\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 914us/step - loss: 1.4151 - mse: 1.4151\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 984us/step - loss: 1.3997 - mse: 1.3997\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 881us/step - loss: 1.5677 - mse: 1.5677\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9696 - mse: 2.9696\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 841us/step - loss: 4.5942 - mse: 4.5942\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9725 - mse: 4.9725\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 830us/step - loss: 2.3580 - mse: 2.3580\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2517 - mse: 2.2517\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9657 - mse: 4.9657\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5830 - mse: 2.5830\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7935 - mse: 1.7935\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6355 - mse: 1.6355\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 988us/step - loss: 1.2904 - mse: 1.2904\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4855 - mse: 1.4855\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 2.3428 - mse: 2.3428\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2872 - mse: 8.2872\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.6063 - mse: 5.6063\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 805us/step - loss: 2.2288 - mse: 2.2288\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 972us/step - loss: 1.3295 - mse: 1.3295\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 818us/step - loss: 1.3686 - mse: 1.3686\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 1.2797 - mse: 1.2797\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 861us/step - loss: 1.8955 - mse: 1.8955\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 763us/step - loss: 8.0570 - mse: 8.0570\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.7053 - mse: 5.7053\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 964us/step - loss: 1.8072 - mse: 1.8072\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 950us/step - loss: 1.2870 - mse: 1.2870\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 767us/step - loss: 1.2741 - mse: 1.2741\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3665 - mse: 1.3665\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6004 - mse: 2.6004\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.0799 - mse: 5.0799\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9045 - mse: 3.9045\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2622 - mse: 4.2622\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4124 - mse: 4.4124\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7944 - mse: 2.7944\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 833us/step - loss: 3.0322 - mse: 3.0322\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0148 - mse: 3.0148\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7085 - mse: 1.7085\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8945 - mse: 1.8945\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1899 - mse: 2.1899\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0522 - mse: 3.0522\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 908us/step - loss: 4.4935 - mse: 4.4935\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 915us/step - loss: 2.3314 - mse: 2.3314\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1960 - mse: 2.1960\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0673 - mse: 3.0673\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 908us/step - loss: 4.5630 - mse: 4.5630\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 5.4239 - mse: 5.4239\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1217 - mse: 4.1217\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.8152 - mse: 3.8152\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2865 - mse: 2.2865\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8795 - mse: 1.8795\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0002 - mse: 3.0002\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.5191 - mse: 4.5191\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9671 - mse: 2.9671\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6520 - mse: 1.6520\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2382 - mse: 1.2382\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2460 - mse: 1.2460\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4163 - mse: 1.4163\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7370 - mse: 2.7370\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0145 - mse: 8.0145\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.3915 - mse: 5.3915\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1377 - mse: 2.1377\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8247 - mse: 1.8247\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9448 - mse: 1.9448\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3046 - mse: 3.3046\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0833 - mse: 3.0833\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.5586 - mse: 5.5586\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6131 - mse: 4.6131\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7816 - mse: 1.7816\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2611 - mse: 1.2611\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 956us/step - loss: 1.2299 - mse: 1.2299\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0654 - mse: 2.0654\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8976 - mse: 3.8976\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7564 - mse: 4.7564\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3711 - mse: 3.3711\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1036 - mse: 3.1036\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6249 - mse: 2.6249\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6077 - mse: 3.6077\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7270 - mse: 3.7270\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1704 - mse: 3.1704\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 849us/step - loss: 2.1791 - mse: 2.1791\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4128 - mse: 2.4128\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 3.6311 - mse: 3.6311\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 852us/step - loss: 4.7733 - mse: 4.7733\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9341 - mse: 3.9341\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 785us/step - loss: 1.8851 - mse: 1.8851\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 876us/step - loss: 1.2790 - mse: 1.2790\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 925us/step - loss: 1.7673 - mse: 1.7673\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 894us/step - loss: 1.1850 - mse: 1.1850\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.8069 - mse: 2.8069\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 844us/step - loss: 8.1547 - mse: 8.1547\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8775 - mse: 4.8775\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7530 - mse: 1.7530\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2211 - mse: 1.2211\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2032 - mse: 1.2032\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7958 - mse: 1.7958\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.5716 - mse: 3.5716\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5495 - mse: 4.5495\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 791us/step - loss: 3.3873 - mse: 3.3873\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 958us/step - loss: 2.6504 - mse: 2.6504\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2121 - mse: 3.2121\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.7837 - mse: 3.7837\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 3.0209 - mse: 3.0209\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1511 - mse: 2.1511\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5448 - mse: 2.5448\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 3.2209 - mse: 3.2209\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 959us/step - loss: 4.3087 - mse: 4.3087\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4894 - mse: 4.4894\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 743us/step - loss: 2.9244 - mse: 2.9244\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 885us/step - loss: 3.0202 - mse: 3.0202\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 803us/step - loss: 1.8510 - mse: 1.8510\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 822us/step - loss: 1.2448 - mse: 1.2448\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 811us/step - loss: 1.6030 - mse: 1.6030\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 840us/step - loss: 1.4066 - mse: 1.4066\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 794us/step - loss: 2.5737 - mse: 2.5737\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 928us/step - loss: 5.0137 - mse: 5.0137\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.5958 - mse: 6.5958\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 774us/step - loss: 5.3390 - mse: 5.3390\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0950 - mse: 2.0950\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1580 - mse: 2.1580\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2374 - mse: 3.2374\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 2.6271 - mse: 2.6271\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7667 - mse: 2.7667\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1831 - mse: 3.1831\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9474 - mse: 1.9474\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 817us/step - loss: 1.1714 - mse: 1.1714\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 731us/step - loss: 1.7508 - mse: 1.7508\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 928us/step - loss: 5.4019 - mse: 5.4019\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 824us/step - loss: 6.0947 - mse: 6.0947\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 806us/step - loss: 1.6026 - mse: 1.6026\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 919us/step - loss: 1.1815 - mse: 1.1815\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 708us/step - loss: 2.1244 - mse: 2.1244\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 883us/step - loss: 5.3045 - mse: 5.3045\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 978us/step - loss: 3.1254 - mse: 3.1254\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 738us/step - loss: 3.1211 - mse: 3.1211\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 959us/step - loss: 2.7372 - mse: 2.7372\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0259 - mse: 2.0259\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 889us/step - loss: 1.3660 - mse: 1.3660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc451324f40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.08104131, -0.08116496,  0.08112586],\n",
       "        [-0.181887  , -0.18198194,  0.18195155],\n",
       "        [-0.12704144, -0.12715095,  0.12711617],\n",
       "        [-0.19801058, -0.1981205 ,  0.19808608],\n",
       "        [ 0.00117878,  0.00079251, -0.00091078],\n",
       "        [-0.00711612, -0.00746485,  0.00735788]], dtype=float32),\n",
       " array([-0.07637643, -0.07665335,  0.07656802], dtype=float32),\n",
       " array([[-0.5253529],\n",
       "        [-1.0904576],\n",
       "        [ 0.8225987]], dtype=float32),\n",
       " array([0.07692301], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.924786]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros_after_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.924786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.055887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.300007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>21.156216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.137249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros_after_fit\n",
       "abbrev                             \n",
       "AL       18.8             17.924786\n",
       "AK       18.1             17.055887\n",
       "AZ       18.6             17.300007\n",
       "AR       22.4             21.156216\n",
       "CA       12.0             12.137249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel = df[['total']].copy()\n",
    "dfsel['pred_zeros_after_fit'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.047686213425837"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_zeros_after_fit)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='ones'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2444.8599]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[0.7389778 ],\n",
       "        [0.8732146 ],\n",
       "        [0.89358294]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 198.9468 - mse: 198.9468\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 36.7605 - mse: 36.7605\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.5509 - mse: 27.5509\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 956us/step - loss: 28.3127 - mse: 28.3127\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4104 - mse: 27.4104\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 923us/step - loss: 26.6115 - mse: 26.6115\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 783us/step - loss: 26.5767 - mse: 26.5767\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 771us/step - loss: 26.1284 - mse: 26.1284\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.5844 - mse: 25.5844\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.7333 - mse: 25.7333\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.3078 - mse: 27.3078\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.5103 - mse: 28.5103\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.1297 - mse: 26.1297\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.6659 - mse: 24.6659\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 911us/step - loss: 23.6926 - mse: 23.6926\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.9382 - mse: 24.9382\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 29.9830 - mse: 29.9830\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.0944 - mse: 27.0944\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.0997 - mse: 30.0997\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.0326 - mse: 23.0326\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.2210 - mse: 22.2210\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.8826 - mse: 21.8826\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 893us/step - loss: 20.1023 - mse: 20.1023\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.9388 - mse: 22.9388\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.7667 - mse: 26.7667\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.8695 - mse: 21.8695\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.6461 - mse: 18.6461\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.3738 - mse: 21.3738\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.5358 - mse: 18.5358\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 925us/step - loss: 24.4536 - mse: 24.4536\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 944us/step - loss: 20.3076 - mse: 20.3076\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.2434 - mse: 18.2434\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.7541 - mse: 16.7541\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.1330 - mse: 16.1330\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8911 - mse: 15.8911\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.3662 - mse: 15.3662\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2646 - mse: 15.2646\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7729 - mse: 15.7729\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.1040 - mse: 16.1040\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.7305 - mse: 20.7305\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.5584 - mse: 15.5584\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4585 - mse: 17.4585\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.7669 - mse: 15.7669\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.7364 - mse: 14.7364\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.5024 - mse: 15.5024\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.3079 - mse: 12.3079\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.9987 - mse: 11.9987\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 917us/step - loss: 12.3893 - mse: 12.3893\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.1521 - mse: 18.1521\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.9559 - mse: 19.9559\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9291 - mse: 10.9291\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7649 - mse: 10.7649\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6029 - mse: 11.6029\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4757 - mse: 10.4757\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 867us/step - loss: 15.2021 - mse: 15.2021\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.7825 - mse: 13.7825\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1974 - mse: 10.1974\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.0172 - mse: 14.0172\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2715 - mse: 12.2715\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5145 - mse: 9.5145\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9209 - mse: 8.9209\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2268 - mse: 12.2268\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7053 - mse: 13.7053\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4090 - mse: 8.4090\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1467 - mse: 8.1467\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0647 - mse: 8.0647\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8324 - mse: 7.8324\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3059 - mse: 13.3059\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.9891 - mse: 18.9891\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8005 - mse: 7.8005\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 893us/step - loss: 8.3898 - mse: 8.3898\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.0060 - mse: 12.0060\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 887us/step - loss: 9.2545 - mse: 9.2545\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9653 - mse: 6.9653\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2324 - mse: 7.2324\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2785 - mse: 7.2785\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 6.7688 - mse: 6.7688\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4041 - mse: 7.4041\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.6971 - mse: 6.6971\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 903us/step - loss: 8.7428 - mse: 8.7428\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5740 - mse: 12.5740\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7436 - mse: 8.7436\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.8193 - mse: 5.8193\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2518 - mse: 7.2518\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 5.6167 - mse: 5.6167\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2404 - mse: 7.2404\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 904us/step - loss: 5.9989 - mse: 5.9989\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.7901 - mse: 5.7901\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.5747 - mse: 5.5747\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.8544 - mse: 4.8544\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7925 - mse: 4.7925\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.5343 - mse: 13.5343\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 938us/step - loss: 11.2057 - mse: 11.2057\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8288 - mse: 4.8288\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.5470 - mse: 5.5470\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5678 - mse: 6.5678\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3173 - mse: 4.3173\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.1841 - mse: 5.1841\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3426 - mse: 4.3426\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.6349 - mse: 4.6349\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.1903 - mse: 6.1903\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9603 - mse: 4.9603\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4233 - mse: 4.4233\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8123 - mse: 9.8123\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 912us/step - loss: 9.8452 - mse: 9.8452\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.7819 - mse: 5.7819\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 866us/step - loss: 3.6978 - mse: 3.6978\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.7780 - mse: 3.7780\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.5014 - mse: 3.5014\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3814 - mse: 3.3814\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9596 - mse: 3.9596\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.1184 - mse: 5.1184\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 6.8306 - mse: 6.8306\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6939 - mse: 9.6939\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1135 - mse: 8.1135\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.0544 - mse: 4.0544\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2592 - mse: 3.2592\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2623 - mse: 3.2623\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3566 - mse: 3.3566\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2426 - mse: 4.2426\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4720 - mse: 4.4720\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.6489 - mse: 4.6489\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1903 - mse: 3.1903\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7875 - mse: 2.7875\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9210 - mse: 2.9210\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2301 - mse: 3.2301\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7359 - mse: 2.7359\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 759us/step - loss: 2.6380 - mse: 2.6380\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.4963 - mse: 3.4963\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6874 - mse: 13.6874\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 966us/step - loss: 8.6179 - mse: 8.6179\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7486 - mse: 4.7486\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9033 - mse: 2.9033\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6365 - mse: 2.6365\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1652 - mse: 3.1652\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 950us/step - loss: 4.2638 - mse: 4.2638\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 930us/step - loss: 4.4304 - mse: 4.4304\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.0294 - mse: 5.0294\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6750 - mse: 2.6750\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3416 - mse: 2.3416\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4635 - mse: 2.4635\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.5489 - mse: 3.5489\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.5593 - mse: 6.5593\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 949us/step - loss: 4.2534 - mse: 4.2534\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8906 - mse: 3.8906\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 904us/step - loss: 2.5130 - mse: 2.5130\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6287 - mse: 2.6287\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4754 - mse: 4.4754\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.5607 - mse: 6.5607\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0115 - mse: 8.0115\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0389 - mse: 3.0389\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3406 - mse: 2.3406\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 716us/step - loss: 2.6411 - mse: 2.6411\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7970 - mse: 2.7970\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8840 - mse: 4.8840\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.8301 - mse: 5.8301\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.3284 - mse: 5.3284\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2957 - mse: 3.2957\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3203 - mse: 2.3203\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9607 - mse: 1.9607\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9295 - mse: 1.9295\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.9685 - mse: 5.9685\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 823us/step - loss: 8.8187 - mse: 8.8187\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 2.5074 - mse: 2.5074\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4311 - mse: 2.4311\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1046 - mse: 4.1046\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1602 - mse: 4.1602\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5978 - mse: 2.5978\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 956us/step - loss: 2.5354 - mse: 2.5354\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 902us/step - loss: 2.9982 - mse: 2.9982\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8889 - mse: 4.8889\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6199 - mse: 3.6199\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3380 - mse: 3.3380\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7822 - mse: 2.7822\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8367 - mse: 1.8367\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1445 - mse: 2.1445\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.4725 - mse: 4.4725\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 934us/step - loss: 4.9671 - mse: 4.9671\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.7507 - mse: 3.7507\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5657 - mse: 2.5657\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6784 - mse: 3.6784\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2528 - mse: 9.2528\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.4934 - mse: 6.4934\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1934 - mse: 2.1934\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9332 - mse: 1.9332\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4091 - mse: 2.4091\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0804 - mse: 3.0804\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.0631 - mse: 4.0631\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4945 - mse: 4.4945\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3492 - mse: 3.3492\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4551 - mse: 2.4551\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 809us/step - loss: 2.9986 - mse: 2.9986\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 887us/step - loss: 3.2670 - mse: 3.2670\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1470 - mse: 4.1470\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 774us/step - loss: 2.8726 - mse: 2.8726\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4588 - mse: 2.4588\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9409 - mse: 3.9409\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6991 - mse: 4.6991\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 954us/step - loss: 6.2172 - mse: 6.2172\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 3.9748 - mse: 3.9748\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6915 - mse: 1.6915\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6997 - mse: 1.6997\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6847 - mse: 1.6847\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 2.5472 - mse: 2.5472\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 887us/step - loss: 7.1161 - mse: 7.1161\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.2708 - mse: 6.2708\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 975us/step - loss: 2.8641 - mse: 2.8641\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 800us/step - loss: 2.9777 - mse: 2.9777\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2818 - mse: 2.2818\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 1.6530 - mse: 1.6530\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 913us/step - loss: 1.9272 - mse: 1.9272\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6240 - mse: 3.6240\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7227 - mse: 7.7227\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.0991 - mse: 7.0991\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9999 - mse: 1.9999\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6709 - mse: 1.6709\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8956 - mse: 1.8956\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6287 - mse: 3.6287\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.4488 - mse: 5.4488\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9937 - mse: 2.9937\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7205 - mse: 1.7205\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6283 - mse: 1.6283\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 1.6179 - mse: 1.6179\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 2.2268 - mse: 2.2268\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 940us/step - loss: 4.7633 - mse: 4.7633\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.4102 - mse: 6.4102\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.0735 - mse: 5.0735\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1070 - mse: 4.1070\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6814 - mse: 1.6814\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5727 - mse: 1.5727\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6349 - mse: 1.6349\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 766us/step - loss: 3.3367 - mse: 3.3367\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.2375 - mse: 6.2375\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8939 - mse: 4.8939\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1041 - mse: 2.1041\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5863 - mse: 1.5863\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5573 - mse: 1.5573\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5676 - mse: 1.5676\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6735 - mse: 1.6735\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2570 - mse: 2.2570\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.2105 - mse: 6.2105\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 866us/step - loss: 9.5213 - mse: 9.5213\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1584 - mse: 2.1584\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5630 - mse: 1.5630\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6321 - mse: 1.6321\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9693 - mse: 1.9693\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 942us/step - loss: 3.5719 - mse: 3.5719\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 942us/step - loss: 4.0205 - mse: 4.0205\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 813us/step - loss: 3.0938 - mse: 3.0938\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2908 - mse: 7.2908\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 4.2680 - mse: 4.2680\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8764 - mse: 1.8764\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6899 - mse: 1.6899\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 826us/step - loss: 1.7828 - mse: 1.7828\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2736 - mse: 4.2736\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 908us/step - loss: 4.1815 - mse: 4.1815\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 864us/step - loss: 2.0976 - mse: 2.0976\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 1.6987 - mse: 1.6987\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7665 - mse: 1.7665\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 1.4984 - mse: 1.4984\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5146 - mse: 1.5146\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6518 - mse: 1.6518\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 818us/step - loss: 5.6599 - mse: 5.6599\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 761us/step - loss: 12.8890 - mse: 12.8890\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 4.3866 - mse: 4.3866\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5841 - mse: 2.5841\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5731 - mse: 2.5731\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 978us/step - loss: 4.0830 - mse: 4.0830\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2200 - mse: 2.2200\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 1.9634 - mse: 1.9634\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 941us/step - loss: 3.4464 - mse: 3.4464\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7535 - mse: 4.7535\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1904 - mse: 3.1904\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 970us/step - loss: 1.6708 - mse: 1.6708\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4522 - mse: 1.4522\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0228 - mse: 2.0228\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0762 - mse: 3.0762\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 902us/step - loss: 6.8534 - mse: 6.8534\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 789us/step - loss: 5.7190 - mse: 5.7190\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 829us/step - loss: 2.2851 - mse: 2.2851\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4516 - mse: 1.4516\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8176 - mse: 1.8176\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6335 - mse: 2.6335\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 906us/step - loss: 2.9819 - mse: 2.9819\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.1768 - mse: 5.1768\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 5.1903 - mse: 5.1903\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6532 - mse: 2.6532\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8878 - mse: 1.8878\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7869 - mse: 1.7869\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0508 - mse: 2.0508\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5019 - mse: 1.5019\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7215 - mse: 1.7215\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.6489 - mse: 5.6489\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.7410 - mse: 6.7410\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.8546 - mse: 2.8546\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3014 - mse: 2.3014\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.8267 - mse: 3.8267\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.8651 - mse: 3.8651\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3114 - mse: 4.3114\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.3600 - mse: 4.3600\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7384 - mse: 2.7384\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8845 - mse: 1.8845\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 2.0831 - mse: 2.0831\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4217 - mse: 1.4217\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8120 - mse: 1.8120\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3175 - mse: 3.3175\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.4787 - mse: 6.4787\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 4.5388 - mse: 4.5388\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6875 - mse: 1.6875\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 852us/step - loss: 1.4031 - mse: 1.4031\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4058 - mse: 1.4058\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0612 - mse: 2.0612\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.4870 - mse: 5.4870\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 6.3440 - mse: 6.3440\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.6805 - mse: 5.6805\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3611 - mse: 2.3611\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7244 - mse: 1.7244\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 802us/step - loss: 1.6263 - mse: 1.6263\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 970us/step - loss: 1.3759 - mse: 1.3759\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3932 - mse: 1.3932\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3901 - mse: 1.3901\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 1.4214 - mse: 1.4214\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 792us/step - loss: 2.4793 - mse: 2.4793\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 919us/step - loss: 9.6203 - mse: 9.6203\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 4.1215 - mse: 4.1215\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1305 - mse: 2.1305\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5369 - mse: 1.5369\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4797 - mse: 1.4797\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1555 - mse: 3.1555\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 5.0963 - mse: 5.0963\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.5501 - mse: 4.5501\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.4171 - mse: 3.4171\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9485 - mse: 1.9485\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 828us/step - loss: 1.6496 - mse: 1.6496\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 829us/step - loss: 2.4160 - mse: 2.4160\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6518 - mse: 4.6518\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1113 - mse: 3.1113\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.2538 - mse: 3.2538\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.8998 - mse: 5.8998\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2425 - mse: 4.2425\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6424 - mse: 1.6424\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 987us/step - loss: 1.3374 - mse: 1.3374\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 1.4895 - mse: 1.4895\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4563 - mse: 1.4563\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.2996 - mse: 5.2996\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0736 - mse: 9.0736\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7683 - mse: 4.7683\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5741 - mse: 1.5741\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5459 - mse: 1.5459\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6285 - mse: 1.6285\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4716 - mse: 1.4716\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9581 - mse: 2.9581\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 845us/step - loss: 8.3039 - mse: 8.3039\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9008 - mse: 3.9008\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0420 - mse: 2.0420\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4715 - mse: 1.4715\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9456 - mse: 1.9456\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 920us/step - loss: 1.9282 - mse: 1.9282\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 823us/step - loss: 1.9836 - mse: 1.9836\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 725us/step - loss: 1.8097 - mse: 1.8097\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 3.1204 - mse: 3.1204\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 794us/step - loss: 7.6144 - mse: 7.6144\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 792us/step - loss: 4.8991 - mse: 4.8991\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 914us/step - loss: 1.4151 - mse: 1.4151\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 984us/step - loss: 1.3997 - mse: 1.3997\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 881us/step - loss: 1.5677 - mse: 1.5677\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9696 - mse: 2.9696\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 841us/step - loss: 4.5942 - mse: 4.5942\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9725 - mse: 4.9725\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 830us/step - loss: 2.3580 - mse: 2.3580\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2517 - mse: 2.2517\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9657 - mse: 4.9657\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5830 - mse: 2.5830\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7935 - mse: 1.7935\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6355 - mse: 1.6355\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 988us/step - loss: 1.2904 - mse: 1.2904\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4855 - mse: 1.4855\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 2.3428 - mse: 2.3428\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2872 - mse: 8.2872\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.6063 - mse: 5.6063\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 805us/step - loss: 2.2288 - mse: 2.2288\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 972us/step - loss: 1.3295 - mse: 1.3295\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 818us/step - loss: 1.3686 - mse: 1.3686\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 1.2797 - mse: 1.2797\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 861us/step - loss: 1.8955 - mse: 1.8955\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 763us/step - loss: 8.0570 - mse: 8.0570\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.7053 - mse: 5.7053\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 964us/step - loss: 1.8072 - mse: 1.8072\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 950us/step - loss: 1.2870 - mse: 1.2870\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 767us/step - loss: 1.2741 - mse: 1.2741\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3665 - mse: 1.3665\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6004 - mse: 2.6004\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.0799 - mse: 5.0799\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9045 - mse: 3.9045\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2622 - mse: 4.2622\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4124 - mse: 4.4124\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7944 - mse: 2.7944\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 833us/step - loss: 3.0322 - mse: 3.0322\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0148 - mse: 3.0148\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7085 - mse: 1.7085\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8945 - mse: 1.8945\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1899 - mse: 2.1899\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0522 - mse: 3.0522\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 908us/step - loss: 4.4935 - mse: 4.4935\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 915us/step - loss: 2.3314 - mse: 2.3314\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1960 - mse: 2.1960\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0673 - mse: 3.0673\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 908us/step - loss: 4.5630 - mse: 4.5630\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 5.4239 - mse: 5.4239\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.1217 - mse: 4.1217\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.8152 - mse: 3.8152\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2865 - mse: 2.2865\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8795 - mse: 1.8795\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0002 - mse: 3.0002\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.5191 - mse: 4.5191\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9671 - mse: 2.9671\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6520 - mse: 1.6520\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2382 - mse: 1.2382\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2460 - mse: 1.2460\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4163 - mse: 1.4163\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7370 - mse: 2.7370\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0145 - mse: 8.0145\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.3915 - mse: 5.3915\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1377 - mse: 2.1377\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8247 - mse: 1.8247\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9448 - mse: 1.9448\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3046 - mse: 3.3046\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0833 - mse: 3.0833\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.5586 - mse: 5.5586\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6131 - mse: 4.6131\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7816 - mse: 1.7816\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2611 - mse: 1.2611\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 956us/step - loss: 1.2299 - mse: 1.2299\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0654 - mse: 2.0654\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8976 - mse: 3.8976\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7564 - mse: 4.7564\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.3711 - mse: 3.3711\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1036 - mse: 3.1036\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6249 - mse: 2.6249\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.6077 - mse: 3.6077\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7270 - mse: 3.7270\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1704 - mse: 3.1704\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 849us/step - loss: 2.1791 - mse: 2.1791\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4128 - mse: 2.4128\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 3.6311 - mse: 3.6311\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 852us/step - loss: 4.7733 - mse: 4.7733\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.9341 - mse: 3.9341\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 785us/step - loss: 1.8851 - mse: 1.8851\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 876us/step - loss: 1.2790 - mse: 1.2790\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 925us/step - loss: 1.7673 - mse: 1.7673\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 894us/step - loss: 1.1850 - mse: 1.1850\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.8069 - mse: 2.8069\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 844us/step - loss: 8.1547 - mse: 8.1547\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.8775 - mse: 4.8775\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7530 - mse: 1.7530\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2211 - mse: 1.2211\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2032 - mse: 1.2032\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7958 - mse: 1.7958\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.5716 - mse: 3.5716\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5495 - mse: 4.5495\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 791us/step - loss: 3.3873 - mse: 3.3873\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 958us/step - loss: 2.6504 - mse: 2.6504\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2121 - mse: 3.2121\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.7837 - mse: 3.7837\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 3.0209 - mse: 3.0209\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1511 - mse: 2.1511\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5448 - mse: 2.5448\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 3.2209 - mse: 3.2209\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 959us/step - loss: 4.3087 - mse: 4.3087\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.4894 - mse: 4.4894\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 743us/step - loss: 2.9244 - mse: 2.9244\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 885us/step - loss: 3.0202 - mse: 3.0202\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 803us/step - loss: 1.8510 - mse: 1.8510\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 822us/step - loss: 1.2448 - mse: 1.2448\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 811us/step - loss: 1.6030 - mse: 1.6030\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 840us/step - loss: 1.4066 - mse: 1.4066\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 794us/step - loss: 2.5737 - mse: 2.5737\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 928us/step - loss: 5.0137 - mse: 5.0137\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.5958 - mse: 6.5958\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 774us/step - loss: 5.3390 - mse: 5.3390\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0950 - mse: 2.0950\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1580 - mse: 2.1580\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2374 - mse: 3.2374\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 2.6271 - mse: 2.6271\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7667 - mse: 2.7667\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.1831 - mse: 3.1831\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9474 - mse: 1.9474\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 817us/step - loss: 1.1714 - mse: 1.1714\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 731us/step - loss: 1.7508 - mse: 1.7508\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 928us/step - loss: 5.4019 - mse: 5.4019\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 824us/step - loss: 6.0947 - mse: 6.0947\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 806us/step - loss: 1.6026 - mse: 1.6026\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 919us/step - loss: 1.1815 - mse: 1.1815\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 708us/step - loss: 2.1244 - mse: 2.1244\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 883us/step - loss: 5.3045 - mse: 5.3045\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 978us/step - loss: 3.1254 - mse: 3.1254\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 738us/step - loss: 3.1211 - mse: 3.1211\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 959us/step - loss: 2.7372 - mse: 2.7372\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0259 - mse: 2.0259\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 889us/step - loss: 1.3660 - mse: 1.3660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc451324f40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.08104131, -0.08116496,  0.08112586],\n",
       "        [-0.181887  , -0.18198194,  0.18195155],\n",
       "        [-0.12704144, -0.12715095,  0.12711617],\n",
       "        [-0.19801058, -0.1981205 ,  0.19808608],\n",
       "        [ 0.00117878,  0.00079251, -0.00091078],\n",
       "        [-0.00711612, -0.00746485,  0.00735788]], dtype=float32),\n",
       " array([-0.07637643, -0.07665335,  0.07656802], dtype=float32),\n",
       " array([[-0.5253529],\n",
       "        [-1.0904576],\n",
       "        [ 0.8225987]], dtype=float32),\n",
       " array([0.07692301], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.924786]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros_after_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.924786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.055887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.300007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>21.156216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.137249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros_after_fit\n",
       "abbrev                             \n",
       "AL       18.8             17.924786\n",
       "AK       18.1             17.055887\n",
       "AZ       18.6             17.300007\n",
       "AR       22.4             21.156216\n",
       "CA       12.0             12.137249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel = df[['total']].copy()\n",
    "dfsel['pred_zeros_after_fit'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.047686213425837"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_zeros_after_fit)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to `glorot_uniform` (default)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `sigmoid` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsel['pred_sigmoid'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sigmoid)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`\n",
    "\n",
    "> - Have they changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `linear` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tanh` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `relu` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the predictions changing? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/optimizers/#available-optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers comparison in GIF ‚Üí https://mlfromscratch.com/optimizers-explained/#adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla's Neural Network Models is composed of 48 models trainned in 70.000 hours of GPU ‚Üí https://tesla.com/ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Year with a 8 GPU Computer ‚Üí https://twitter.com/thirdrowtesla/status/1252723358342377472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gradient Descent `SGD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `compile()` the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsel['pred_gsd'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sgd)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`\n",
    "\n",
    "> - Have they changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `ADAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `RMSPROP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it take different times to get the best accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `binary_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sparse_categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mean_squared_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the end, what should be a feasible configuration of the Neural Network for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `kernel_initializer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `activation` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `optimizer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `loss` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network's importance to find **Non-Linear Patterns** in the Data\n",
    "\n",
    "> - The number of Neurons & Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87287&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Mathematical Formula\n",
    "- Weights / Kernel Initializer\n",
    "- Loss Function\n",
    "- Activation Function\n",
    "- Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What cannot you change arbitrarily of a Neural Network?\n",
    "\n",
    "- Input Neurons\n",
    "- Output Neurons\n",
    "- Loss Functions\n",
    "- Activation Functions"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jes√∫s L√≥pez @sotastica"
   }
  ],
  "interpreter": {
   "hash": "a2b8701b642343483c5f5e717bcb0768c6b951acf38d76a6fc8ea01492bda71d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
